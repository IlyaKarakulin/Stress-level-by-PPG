{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_lable = 700\n",
    "frequency_PPG = 64\n",
    "frequency_ACC = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranges(indices):\n",
    "    groups = []\n",
    "    current_group = [indices[0]]\n",
    "    time_interval = []\n",
    "\n",
    "    for i in range(1, len(indices)):\n",
    "        if indices[i] == indices[i - 1] + 1:  # Проверяем, непрерывный ли индекс\n",
    "            current_group.append(indices[i])\n",
    "        else:\n",
    "            groups.append(current_group)  # Сохраняем текущую группу\n",
    "            current_group = [indices[i]]  # Начинаем новую группу\n",
    "\n",
    "    # Добавляем последнюю группу\n",
    "    groups.append(current_group)\n",
    "\n",
    "    # Выводим начальные и конечные индексы для каждой группы\n",
    "    for group in groups:\n",
    "        start = group[0]\n",
    "        end = group[-1]\n",
    "        tmp = (int(start / 700), int(end / 700))\n",
    "        time_interval.append(tmp)\n",
    "\n",
    "    return time_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interval(Sx_lable):\n",
    "    Sx_lable_df = pd.DataFrame(Sx_lable, columns=['val'])\n",
    "\n",
    "    indices_4 = Sx_lable_df[Sx_lable_df['val'] == 4].index # интервалы где чел медитирует\n",
    "    time_interval_4 = ranges(indices_4) # Группируем непрерывные индексы \n",
    "\n",
    "    indices_2 = Sx_lable_df[Sx_lable_df['val'] == 2].index # интервалы где стрессует\n",
    "    time_interval_2 = ranges(indices_2)\n",
    "\n",
    "    return time_interval_4, time_interval_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_motion_artifacts(acc_data, ppg_data, threshold, window_size):\n",
    "    # 1. Вычисляем разницу между соседними измерениями акселерометра\n",
    "    acc_diff = np.vstack((np.zeros((1, 3)), np.abs(np.diff(acc_data, axis=0))))\n",
    "\n",
    "    kernel = np.ones(window_size)/window_size\n",
    "    smoothed_diff = np.zeros_like(acc_diff)\n",
    "    \n",
    "    for i in range(3):  # Обрабатываем каждый из 3 каналов\n",
    "        smoothed_diff[:, i] = np.convolve(acc_diff[:, i], kernel, mode='same')\n",
    "    \n",
    "    mask_acc = np.all(acc_diff < threshold, axis=1)\n",
    "\n",
    "    # 3. Учитываем соотношение частот 32 Гц -> 64 Гц (1:2)\n",
    "    mask_ppg = np.repeat(mask_acc, frequency_PPG // frequency_ACC)\n",
    "\n",
    "    if(len(ppg_data) > len(mask_ppg)):\n",
    "        ppg_data = ppg_data[:len(mask_ppg)]\n",
    "    else:\n",
    "        mask_ppg = mask_ppg[:len(ppg_data)]\n",
    "\n",
    "    if(len(acc_data) > len(mask_acc)):\n",
    "        acc_data = acc_data[:len(mask_acc)]\n",
    "    else:\n",
    "        mask_acc = mask_acc[:len(acc_data)]\n",
    "    \n",
    "    # 5. Применяем маску\n",
    "    filtered_ppg = ppg_data[mask_ppg]\n",
    "    filtered_acc = acc_data[mask_acc]\n",
    "    \n",
    "    return filtered_ppg, filtered_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_PGG_amplitude_anomaly(acc_data, ppg_data, threshold, min_valid_len):\n",
    "    mask_pgg = np.squeeze(np.abs(ppg_data) < threshold).astype(int)    \n",
    "    diff = np.diff(mask_pgg) # np.insert(np.diff(mask_pgg), 0, 0)\n",
    "\n",
    "    starts = np.where(diff == 1)[0] + 1   # Начала групп\n",
    "    ends = np.where(diff == -1)[0] + 1    # Концы групп\n",
    "    \n",
    "    # Обработка случаев, когда маска начинается или заканчивается True\n",
    "    if mask_pgg[0]:\n",
    "        starts = np.insert(starts, 0, 0)\n",
    "    if mask_pgg[-1]:\n",
    "        ends = np.append(ends, len(mask_pgg))\n",
    "    \n",
    "    # Фильтруем группы по длине\n",
    "    valid_groups = [(start, end) for start, end in zip(starts, ends) if (end - start) >= min_valid_len]\n",
    "    \n",
    "    # Собираем данные ФПГ из валидных групп\n",
    "    filtered_ppg = np.concatenate([ppg_data[start:end] for start, end in valid_groups])\n",
    "    filtered_acc = np.concatenate([acc_data[start // 2 : end // 2] for start, end in valid_groups]) # Из-за округления данные могут съехать на несколько единиц\n",
    "    \n",
    "    return filtered_ppg, filtered_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stress_lvl(stai):\n",
    "    return stai.split(\";\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PGG_and_ACC(Sx):\n",
    "    time_interval_medit, time_interval_stress = find_interval(Sx['label'])\n",
    "\n",
    "    PPG_Sx = np.squeeze(Sx['signal']['wrist']['BVP']) # данные с фотоплетизмограммы\n",
    "    ACC_Sx = np.squeeze(Sx['signal']['wrist']['ACC']) # данные акселерометра\n",
    "\n",
    "    PPG_medit = PPG_Sx[frequency_PPG * time_interval_medit[0][0] : frequency_PPG * time_interval_medit[0][1]]\n",
    "    ACC_medit = ACC_Sx[frequency_ACC * time_interval_medit[0][0] : frequency_ACC * time_interval_medit[0][1]]\n",
    "\n",
    "    PGG_stress = PPG_Sx[frequency_PPG * time_interval_stress[0][0] : frequency_PPG * time_interval_stress[0][1]]\n",
    "    ACC_stress = ACC_Sx[frequency_ACC * time_interval_stress[0][0] : frequency_ACC * time_interval_stress[0][1]]\n",
    "\n",
    "    # plt.figure(figsize=(200, 6))\n",
    "    # plt.plot(PPG_medit)\n",
    "    # plt.savefig('PPG_stress_S4.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # filtred_PPG_stress, filtred_ACC_stress = filt_PGG_amplitude_anomaly(ACC_stress, PGG_stress, 50, 64 * 3)\n",
    "    # filtred_PPG_medit, filtred_ACC_medit = filt_PGG_amplitude_anomaly(ACC_medit, PPG_medit, 50, 64 * 3)\n",
    "    \n",
    "    # filtred_PPG_stress, filtred_ACC_stress = remove_motion_artifacts(filtred_ACC_stress, filtred_PPG_stress, 5, 3)\n",
    "    # filtred_PPG_medit, filtred_ACC_medit = remove_motion_artifacts(filtred_ACC_medit, filtred_PPG_medit, 5, 3)\n",
    "\n",
    "    return PGG_stress, ACC_stress, PPG_medit, ACC_medit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drow_data(data_dict, Sx):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(200, 6))\n",
    "    ax1.plot(data_dict[Sx]['PPG_stress'], color='red')\n",
    "    ax1.grid(True)\n",
    "    ax1.tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "    ax1.set_ylim(-50, 50)\n",
    "    ax2.plot(data_dict[Sx]['ACC_stress'])\n",
    "    ax2.grid(True)  \n",
    "    ax2.set_ylim(-128, 127)\n",
    "    ax2.tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "    plt.savefig(f'./init_data/PPG_ACC_st_{Sx}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(200, 6))\n",
    "    ax1.plot(data_dict[Sx]['PPG_medit'], color='red')\n",
    "    ax1.grid(True)\n",
    "    ax1.tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "    ax1.set_ylim(-50, 50)\n",
    "    ax2.plot(data_dict[Sx]['ACC_medit'])\n",
    "    ax2.grid(True)\n",
    "    ax2.set_ylim(-128, 127)\n",
    "    ax2.tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "    plt.savefig(f'./init_data/PPG_ACC_md_{Sx}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folders(path):\n",
    "    all_items = os.listdir(path)\n",
    "    list_user = [item for item in all_items if os.path.isdir(os.path.join(path, item))]\n",
    "    \n",
    "    return list_user\n",
    "\n",
    "list_user = get_folders('/home/ilya/Downloads/WESAD_old/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person_id in list_user:\n",
    "    data_of_person = pd.read_pickle(f'/home/ilya/Downloads/WESAD_old/{person_id}/{person_id}.pkl')\n",
    "    filtred_PPG_stress, filtred_ACC_stress, filtred_PPG_medit, filtred_ACC_medit = get_PGG_and_ACC(data_of_person)\n",
    "\n",
    "    with open(f'/home/ilya/Downloads/WESAD_old/{person_id}/{person_id}_quest.csv', 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    lines = [line.strip() for line in lines]\n",
    "    order = lines[1].split(\";\")[1:8]\n",
    "    # print(order)\n",
    "\n",
    "    index_stress = order.index('TSST')\n",
    "    index_medit = order.index('Medi 1')\n",
    "\n",
    "    stai_lines = [line for line in lines if line.startswith(\"# STAI;\")]\n",
    "    # print(stai_lines[index_stress], get_stress_lvl(stai_lines[index_stress]))\n",
    "    # print(stai_lines[index_medit], get_stress_lvl(stai_lines[index_medit]))\n",
    "\n",
    "    lvl_stress_for_stress = get_stress_lvl(stai_lines[index_stress])\n",
    "    lvl_stress_for_medit = get_stress_lvl(stai_lines[index_medit])\n",
    "\n",
    "    data_dict[person_id] = dict(\n",
    "        {    \n",
    "        'PPG_stress': filtred_PPG_stress,\n",
    "        'ACC_stress': filtred_ACC_stress,\n",
    "        'stress_lvl_for_stress': lvl_stress_for_stress,\n",
    "        'PPG_medit': filtred_PPG_medit,\n",
    "        'ACC_medit': filtred_ACC_medit,\n",
    "        'stress_lvl_for_medit': lvl_stress_for_medit\n",
    "        }\n",
    "    )\n",
    "\n",
    "    drow_data(data_dict, person_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.pkl', 'wb') as file:\n",
    "    pickle.dump(data_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOBES",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
